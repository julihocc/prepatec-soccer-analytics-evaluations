# Ejercicios de Pr√°ctica - Bloque 3: Mi Primera Predicci√≥n con Datos de F√∫tbol

**Curso:** Introducci√≥n a Data Science con F√∫tbol  
**Bloque:** 3 - Machine Learning y Predicci√≥n  
**Peso en calificaci√≥n:** 25% del Bloque 3  
**Modalidad:** Pr√°ctica aut√≥noma con soporte docente

## Informaci√≥n General

Los ejercicios de pr√°ctica est√°n dise√±ados para **reforzar y ampliar** las competencias desarrolladas en los ejercicios semanales, proporcionando oportunidades adicionales de experimentaci√≥n y aprendizaje aut√≥nomo en machine learning aplicado a datos deportivos.

### Objetivos de los Ejercicios de Pr√°ctica

1. **Experimentaci√≥n libre** con t√©cnicas de machine learning avanzadas
2. **Pr√°ctica adicional** en √°reas donde el estudiante identifique debilidades
3. **Exploraci√≥n de t√©cnicas** no cubiertas completamente en ejercicios semanales
4. **Desarrollo de portfolio** personal de proyectos de data science
5. **Preparaci√≥n intensiva** para el proyecto final del bloque

### Estructura y Flexibilidad

- **4 ejercicios pr√°cticos** con diferentes niveles de dificultad
- **Elecci√≥n libre**: Estudiantes eligen 3 de 4 ejercicios seg√∫n sus intereses
- **Ritmo personalizado**: Plazos flexibles con entregas escalonadas
- **Soporte continuo**: Mentor√≠as semanales opcionales
- **Evaluaci√≥n formativa**: Enfoque en aprendizaje m√°s que calificaci√≥n

---

## Ejercicio de Pr√°ctica 1: Experimentaci√≥n con Algoritmos Avanzados

### Descripci√≥n
Implementa y compara algoritmos de machine learning no cubiertos en profundidad en las semanas regulares, explorando su aplicabilidad espec√≠fica a datos de f√∫tbol.

### Objetivos de Aprendizaje
- Explorar algoritmos avanzados como XGBoost, LightGBM, CatBoost
- Implementar redes neuronales b√°sicas para clasificaci√≥n
- Comparar rendimiento con m√©todos tradicionales
- Analizar cu√°ndo usar cada tipo de algoritmo

### Datasets Proporcionados
- `futbol_algoritmos_avanzados.csv`: 1,500 partidos con 40+ variables
- `jugadores_metricas_detalladas.csv`: Estad√≠sticas avanzadas de 150 jugadores
- `equipos_rendimiento_historico.csv`: Datos hist√≥ricos de 30 equipos

### Tareas Espec√≠ficas

#### Parte A: Gradient Boosting Avanzado (40%)
1. **Implementaci√≥n de XGBoost**
   - Configura XGBoost para predicci√≥n de resultados
   - Optimiza hiperpar√°metros usando Bayesian Optimization
   - Analiza importancia de features con SHAP values
   - Compara con Random Forest y Logistic Regression

2. **LightGBM para datos categ√≥ricos**
   - Implementa LightGBM con categorical features nativas
   - Analiza velocidad de entrenamiento vs precisi√≥n
   - Optimiza memory usage para datasets grandes
   - Implementa early stopping para prevenir overfitting

#### Parte B: Redes Neuronales B√°sicas (35%)
1. **Perceptron Multicapa**
   - Dise√±a red neuronal simple (2-3 capas ocultas)
   - Experimenta con diferentes activation functions
   - Implementa regularizaci√≥n (dropout, batch normalization)
   - Compara con algoritmos tradicionales

2. **An√°lisis de arquitectura**
   - Experimenta con diferentes n√∫meros de neuronas
   - Analiza curvas de loss durante entrenamiento
   - Implementa callbacks para monitoring
   - Eval√∫a interpretabilidad vs performance

#### Parte C: Comparaci√≥n Sistem√°tica (25%)
1. **Benchmarking completo**
   - Compara todos los algoritmos implementados
   - Usa validaci√≥n cruzada temporal consistente
   - Analiza trade-offs entre velocidad y precisi√≥n
   - Documenta cu√°ndo usar cada algoritmo

2. **An√°lisis de casos espec√≠ficos**
   - Identifica scenarios donde cada algoritmo excede
   - Analiza comportamiento con datos desbalanceados
   - Eval√∫a robustez ante outliers
   - Documenta recomendaciones pr√°cticas

### Entregables
- **Notebook comparativo**: Implementaci√≥n y an√°lisis de todos los algoritmos
- **Reporte de benchmarking**: Comparaci√≥n sistem√°tica con recomendaciones
- **C√≥digo modular**: Funciones reutilizables para cada algoritmo
- **Visualizaciones**: Gr√°ficos de performance y interpretabilidad

### Criterios de Evaluaci√≥n
- **Implementaci√≥n correcta** (40%): Algoritmos funcionando sin errores
- **An√°lisis comparativo** (30%): Comparaci√≥n sistem√°tica y insights
- **Interpretabilidad** (20%): An√°lisis de por qu√© funcionan los modelos
- **Documentaci√≥n** (10%): C√≥digo limpio y explicaciones claras

---

## Ejercicio de Pr√°ctica 2: Feature Engineering Avanzado y Selecci√≥n Autom√°tica

### Descripci√≥n
Desarrolla t√©cnicas avanzadas de ingenier√≠a de caracter√≠sticas espec√≠ficas para datos deportivos, implementando m√©todos autom√°ticos de selecci√≥n y creaci√≥n de variables.

### Objetivos de Aprendizaje
- Crear features complejas espec√≠ficas para f√∫tbol
- Implementar m√©todos autom√°ticos de feature selection
- Desarrollar pipelines de transformaci√≥n robustos
- Analizar impacto cuantitativo de diferentes tipos de features

### Datasets Proporcionados
- `partidos_completos_temporales.csv`: Datos temporales detallados
- `jugadores_eventos_partido.csv`: Eventos individuales por jugador
- `equipos_tacticas_formaciones.csv`: Datos t√°cticos y formaciones
- `factores_contextuales_extendidos.csv`: Variables contextuales amplias

### Tareas Espec√≠ficas

#### Parte A: Feature Engineering Deportivo (50%)
1. **Variables de momentum y forma**
   - Crea variables de racha (√∫ltimos 3, 5, 10 partidos)
   - Implementa weighted moving averages por rendimiento
   - Desarrolla m√©tricas de consistency (varianza de rendimiento)
   - Crea features de improvement trend (tendencia de mejora)

2. **Variables de contexto y presi√≥n**
   - Desarrolla m√©tricas de importancia del partido
   - Crea features de pressure situations (situaciones de presi√≥n)
   - Implementa variables de rivalidad hist√≥rica
   - Desarrolla m√©tricas de expectativa vs realidad

3. **Variables de interacci√≥n compleja**
   - Crea features de interacci√≥n entre equipos espec√≠ficos
   - Desarrolla m√©tricas de match-up favorability
   - Implementa variables de adaptaci√≥n t√°ctica
   - Crea features de factor cancha espec√≠ficos

#### Parte B: Selecci√≥n Autom√°tica de Features (30%)
1. **M√©todos univariantes**
   - Implementa chi-square test para features categ√≥ricas
   - Usa mutual information para features continuas
   - Aplica ANOVA F-test para comparaci√≥n de grupos
   - Compara resultados de diferentes m√©todos

2. **M√©todos multivariantes**
   - Implementa Recursive Feature Elimination (RFE)
   - Usa LASSO regularization para selecci√≥n autom√°tica
   - Implementa Random Forest feature importance
   - Aplica Boruta algorithm para selecci√≥n robusta

#### Parte C: Pipeline de Transformaci√≥n (20%)
1. **Preprocessing automatizado**
   - Desarrolla pipeline completo de transformaci√≥n
   - Implementa manejo autom√°tico de missing values
   - Crea transformaciones espec√≠ficas por tipo de variable
   - Implementa validation de consistencia de datos

2. **Optimizaci√≥n de pipeline**
   - Optimiza orden de transformaciones
   - Implementa caching para operaciones costosas
   - Desarrolla sistema de rollback para errores
   - Crea logging detallado de transformaciones

### Entregables
- **Librer√≠a de features**: M√≥dulo Python con funciones de feature engineering
- **Pipeline automatizado**: Sistema completo de transformaci√≥n
- **An√°lisis de impacto**: Documento analizando efectividad de cada tipo de feature
- **Casos de estudio**: Ejemplos espec√≠ficos donde nuevas features mejoran predicci√≥n

### Criterios de Evaluaci√≥n
- **Creatividad en features** (35%): Originalidad y relevancia deportiva
- **Implementaci√≥n t√©cnica** (25%): C√≥digo eficiente y robusto
- **Impacto medible** (25%): Mejoras cuantificables en modelos
- **Reusabilidad** (15%): C√≥digo modular y documentado

---

## Ejercicio de Pr√°ctica 3: Sistemas de Ensemble y Meta-Learning

### Descripci√≥n
Implementa t√©cnicas avanzadas de ensemble learning y meta-learning para crear sistemas de predicci√≥n robustos que combinen m√∫ltiples modelos efectivamente.

### Objetivos de Aprendizaje
- Implementar diferentes tipos de ensemble methods
- Desarrollar sistemas de meta-learning para combinar predictores
- Analizar trade-offs entre diversidad y precisi√≥n en ensembles
- Crear sistemas de voting inteligentes

### Datasets Proporcionados
- `predicciones_multiples_modelos.csv`: Predicciones de 10 modelos base
- `metadatos_partidos.csv`: Informaci√≥n contextual para meta-learning
- `rendimiento_historico_modelos.csv`: Performance hist√≥rica de modelos
- `partidos_validacion_ensemble.csv`: Datos para validar ensembles

### Tareas Espec√≠ficas

#### Parte A: Ensemble Methods B√°sicos (35%)
1. **Voting ensembles**
   - Implementa hard voting para clasificaci√≥n
   - Desarrolla soft voting con weighted probabilities
   - Experimenta con diferentes esquemas de weights
   - Analiza cu√°ndo voting mejora performance individual

2. **Bagging avanzado**
   - Implementa bagging con diferentes tipos de sampling
   - Experimenta con feature bagging adem√°s de row bagging
   - Desarrolla out-of-bag error estimation
   - Analiza bias-variance trade-off en bagging

#### Parte B: Stacking y Meta-Learning (40%)
1. **Stacking implementation**
   - Implementa 2-level stacking con cross-validation
   - Experimenta con diferentes meta-learners
   - Desarrolla feature engineering para meta-level
   - Previene data leakage en stacking

2. **Meta-learning avanzado**
   - Implementa dynamic ensemble selection
   - Desarrolla context-aware model selection
   - Crea meta-features basadas en caracter√≠sticas del partido
   - Implementa learning to rank para ensemble weights

#### Parte C: Ensemble Optimization (25%)
1. **Diversity optimization**
   - Implementa m√©tricas de diversity entre modelos
   - Optimiza trade-off entre accuracy y diversity
   - Desarrolla algoritmos de model selection para ensembles
   - Analiza correlaci√≥n entre errores de modelos

2. **Adaptive ensembles**
   - Implementa ensembles que se adaptan por tipo de partido
   - Desarrolla system para re-weighting din√°mico
   - Crea monitoring de degradation de ensemble
   - Implementa sistema de retraining autom√°tico

### Entregables
- **Sistema de ensemble**: Pipeline completo de ensemble learning
- **Meta-learner**: Sistema inteligente de combinaci√≥n de modelos
- **An√°lisis de diversidad**: Estudio de trade-offs en ensemble design
- **Dashboard de monitoring**: Herramienta para monitorear ensemble performance

### Criterios de Evaluaci√≥n
- **Sofisticaci√≥n t√©cnica** (40%): Complejidad y correctness de implementaci√≥n
- **Mejoras de performance** (30%): Gains measurables sobre modelos individuales
- **An√°lisis te√≥rico** (20%): Comprensi√≥n de por qu√© funcionan los ensembles
- **Herramientas pr√°cticas** (10%): Utilidad de sistemas desarrollados

---

## Ejercicio de Pr√°ctica 4: An√°lisis de Interpretabilidad y Explicabilidad

### Descripci√≥n
Desarrolla t√©cnicas avanzadas para interpretar y explicar modelos de machine learning en el contexto deportivo, creando herramientas para comunicar insights a stakeholders no t√©cnicos.

### Objetivos de Aprendizaje
- Implementar t√©cnicas de interpretabilidad global y local
- Desarrollar visualizaciones efectivas para explicar modelos
- Crear narrativas comprensibles sobre decisiones del modelo
- Analizar sesgos y limitaciones de modelos en contextos deportivos

### Datasets Proporcionados
- `modelos_entrenados_pickles/`: Modelos pre-entrenados para an√°lisis
- `casos_estudio_interpretabilidad.csv`: Casos espec√≠ficos para an√°lisis detallado
- `stakeholder_questions.json`: Preguntas t√≠picas de diferentes audiencias
- `sesgo_evaluacion_datos.csv`: Datos para an√°lisis de bias

### Tareas Espec√≠ficas

#### Parte A: Interpretabilidad Global (40%)
1. **Feature importance avanzado**
   - Implementa permutation importance para diferentes m√©tricas
   - Desarrolla feature importance stability analysis
   - Crea visualizaciones de importancia por contexto
   - Analiza consistencia de importancia entre modelos

2. **An√°lisis de interacciones**
   - Implementa H-statistic para medir interacciones
   - Desarrolla visualizaciones de partial dependence plots
   - Crea accumulated local effects plots
   - Analiza feature interactions espec√≠ficas del f√∫tbol

#### Parte B: Interpretabilidad Local (35%)
1. **LIME implementation**
   - Implementa LIME para instancias espec√≠ficas
   - Adapta LIME para features deportivas espec√≠ficas
   - Desarrolla estrategias de perturbation apropiadas
   - Crea visualizaciones intuitivas de explicaciones LIME

2. **SHAP values avanzado**
   - Implementa SHAP para diferentes tipos de modelos
   - Desarrolla explicaciones de fuerza (force plots)
   - Crea summary plots por diferentes segmentos
   - Implementa SHAP interaction values

#### Parte C: Comunicaci√≥n y Narrativa (25%)
1. **Dashboards interactivos**
   - Desarrolla dashboard para explorar interpretabilidad
   - Crea interfaces espec√≠ficas para diferentes stakeholders
   - Implementa explanations adaptadas por audiencia
   - Desarrolla templates de reportes autom√°ticos

2. **An√°lisis de sesgos**
   - Implementa detecci√≥n de bias en modelos
   - Analiza fairness across different team types
   - Desarrolla m√©tricas de equidad en predicciones
   - Crea recomendaciones para mitigar sesgos

### Entregables
- **Toolkit de interpretabilidad**: Conjunto de herramientas para an√°lisis
- **Dashboard interactivo**: Interface para explorar modelos
- **Casos de estudio**: An√°lisis detallados de decisiones espec√≠ficas
- **Gu√≠a de comunicaci√≥n**: Manual para explicar modelos a diferentes audiencias

### Criterios de Evaluaci√≥n
- **Profundidad t√©cnica** (35%): Sofisticaci√≥n de an√°lisis de interpretabilidad
- **Calidad de visualizaciones** (25%): Effectiveness de gr√°ficos y dashboards
- **Claridad de comunicaci√≥n** (25%): Capacidad de explicar conceptos complejos
- **Relevancia pr√°ctica** (15%): Utilidad para stakeholders reales

---

## Metodolog√≠a de Trabajo y Soporte

### Estructura de Mentor√≠as

#### Sesiones Grupales Semanales (1 hora)
- **Lunes**: Revisi√≥n de conceptos y resoluci√≥n de dudas t√©cnicas
- **Mi√©rcoles**: Presentaci√≥n de avances y peer review
- **Viernes**: Troubleshooting y optimizaci√≥n de c√≥digo

#### Mentor√≠as Individuales (30 minutos cada 2 semanas)
- **Revisi√≥n personalizada** de progreso individual
- **Orientaci√≥n espec√≠fica** seg√∫n intereses del estudiante
- **Feedback detallado** sobre calidad de implementaci√≥n
- **Planificaci√≥n** de siguientes pasos de aprendizaje

### Recursos de Apoyo

#### Documentaci√≥n T√©cnica
- **Templates de c√≥digo**: Estructuras base para cada ejercicio
- **Datasets documentados**: Diccionarios de datos completos
- **Gu√≠as de implementaci√≥n**: Paso a paso para t√©cnicas complejas
- **Referencias acad√©micas**: Papers relevantes para profundizar

#### Herramientas Proporcionadas
- **Ambiente de desarrollo**: Jupyter Lab con extensiones
- **Librer√≠as pre-instaladas**: sklearn, xgboost, lightgbm, shap, lime
- **Datasets preprocessados**: Datos listos para experimentaci√≥n
- **Visualizaci√≥n tools**: Plotly, seaborn, matplotlib configurados

### Calendario y Entregas

#### Cronograma Flexible
- **Semanas 1-2**: Selecci√≥n de ejercicios y planificaci√≥n
- **Semanas 3-8**: Desarrollo de ejercicios elegidos
- **Semanas 9-10**: Refinamiento y documentaci√≥n
- **Semana 11**: Presentaciones finales y peer review

#### Entregas Escalonadas
- **25% avance (Semana 4)**: Implementaci√≥n b√°sica funcionando
- **75% avance (Semana 7)**: An√°lisis completo con resultados preliminares
- **100% final (Semana 10)**: Documentaci√≥n completa y presentaci√≥n

### Evaluaci√≥n y Feedback

#### Criterios Transversales
- **Rigor t√©cnico**: Correctness y sophistication de implementaci√≥n
- **Innovaci√≥n**: Creatividad en enfoques y soluciones
- **Aplicabilidad**: Relevancia pr√°ctica para problemas reales
- **Comunicaci√≥n**: Claridad en documentaci√≥n y presentaci√≥n

#### Feedback Continuo
- **Revisiones de c√≥digo**: Comentarios en commits y pull requests
- **Evaluaci√≥n de avances**: Feedback detallado en checkpoints
- **Peer review**: Evaluaci√≥n entre compa√±eros con r√∫bricas
- **Auto-evaluaci√≥n**: Reflexi√≥n estructurada sobre aprendizaje

---

## Integraci√≥n con Proyecto Final

### Preparaci√≥n para Proyecto Final
Los ejercicios de pr√°ctica est√°n dise√±ados para **preparar directamente** para el proyecto final del bloque:

#### Conexiones Espec√≠ficas
- **Ejercicio 1** ‚Üí **Fase 2 del proyecto**: Modelado y optimizaci√≥n avanzada
- **Ejercicio 2** ‚Üí **Fase 1 del proyecto**: Feature engineering estrat√©gico
- **Ejercicio 3** ‚Üí **Fase 3 del proyecto**: Sistemas robustos de producci√≥n
- **Ejercicio 4** ‚Üí **Fase 4 del proyecto**: Comunicaci√≥n y aplicaci√≥n

#### Reutilizaci√≥n de C√≥digo
- **Librer√≠as desarrolladas**: M√≥dulos directamente reutilizables
- **Pipelines creados**: Infrastructura para proyecto final
- **An√°lisis realizados**: Insights aplicables a dataset final
- **Herramientas construidas**: Utilities para desarrollo r√°pido

### Portfolio Profesional
Los ejercicios de pr√°ctica contribuyen a construir un **portfolio s√≥lido**:

#### Componentes de Portfolio
- **Diversidad t√©cnica**: M√∫ltiples t√©cnicas y enfoques demostrados
- **Profundidad anal√≠tica**: An√°lisis detallados y insights valiosos
- **Herramientas pr√°cticas**: C√≥digo reutilizable y bien documentado
- **Comunicaci√≥n efectiva**: Capacidad de explicar conceptos complejos

#### Preparaci√≥n Profesional
- **Experiencia pr√°ctica**: Trabajo con problemas reales complejos
- **Habilidades t√©cnicas**: Competencias demandadas en la industria
- **Capacidad de innovaci√≥n**: Desarrollo de soluciones creativas
- **Colaboraci√≥n efectiva**: Trabajo en equipo y peer review

---

**Los ejercicios de pr√°ctica representan una oportunidad √∫nica para profundizar en machine learning avanzado mientras desarrollas un portfolio profesional s√≥lido. ¬°Aprovecha esta flexibilidad para explorar tus intereses espec√≠ficos en data science deportivo!** üöÄ‚öΩü§ñ

**Peso total:** 25% del Bloque 3 (6.25% de la calificaci√≥n final del curso)  
**Modalidad:** Elecci√≥n flexible de 3 de 4 ejercicios seg√∫n intereses  
**Enfoque:** Experimentaci√≥n y profundizaci√≥n en t√©cnicas avanzadas  
**Objetivo:** Preparaci√≥n intensiva para proyecto final y desarrollo profesional
